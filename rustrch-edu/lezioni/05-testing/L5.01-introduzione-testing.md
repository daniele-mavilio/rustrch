## Teoria

Il testing è una fase cruciale nello sviluppo di qualsiasi software, e Rust non fa eccezione. Quando si costruisce un motore di ricerca, il testing diventa ancora più importante perché garantisce che il sistema funzioni correttamente e in modo efficiente. In questa sezione, esploreremo l'importanza del testing e come può aiutare a ottimizzare le prestazioni del motore di ricerca.

Il testing può essere suddiviso in diverse categorie, ognuna delle quali ha un ruolo specifico nel garantire la qualità del software. I test unitari, ad esempio, verificano che singole funzioni o moduli funzionino come previsto. I test di integrazione, invece, assicurano che diversi componenti del sistema interagiscano correttamente tra loro. Infine, i test di sistema verificano che l'intero sistema funzioni come previsto in un ambiente reale.

Oltre a garantire la correttezza del software, il testing può anche aiutare a identificare e risolvere problemi di prestazioni. Ad esempio, attraverso il benchmarking, è possibile misurare le prestazioni del sistema e identificare eventuali colli di bottiglia. Questo permette di ottimizzare il codice per migliorare l'efficienza e la velocità del motore di ricerca.

## Esempio

Immaginiamo di avere un motore di ricerca che deve indicizzare un gran numero di documenti. Senza un adeguato testing, potremmo non accorgerci che il processo di indicizzazione è lento o che la ricerca non restituisce i risultati corretti. Attraverso il testing, possiamo verificare che ogni componente del motore di ricerca funzioni correttamente e che il sistema nel suo complesso sia efficiente.

Ad esempio, possiamo scrivere un test unitario per verificare che la funzione di tokenizzazione dei documenti funzioni correttamente. Questo test potrebbe verificare che una stringa di input venga suddivisa nei token corretti. Successivamente, possiamo scrivere un test di integrazione per verificare che il modulo di indicizzazione interagisca correttamente con il modulo di tokenizzazione. Infine, possiamo eseguire un benchmark per misurare il tempo necessario per indicizzare un gran numero di documenti e identificare eventuali problemi di prestazioni.

## Pseudocodice

```rust
// Definizione di una funzione di tokenizzazione
fn tokenize(document: &str) -> Vec<String> {
    // Suddivide il documento in token
    document.split_whitespace().map(|s| s.to_string()).collect()
}

// Test unitario per la funzione di tokenizzazione
#[test]
fn test_tokenize() {
    let document = "Hello world";
    let tokens = tokenize(document);
    assert_eq!(tokens, vec!["Hello", "world"]);
}

// Funzione di indicizzazione
fn index_documents(documents: Vec<String>) -> HashMap<String, Vec<String>> {
    let mut index = HashMap::new();
    for doc in documents {
        let tokens = tokenize(&doc);
        for token in tokens {
            index.entry(token).or_insert_with(Vec::new).push(doc.clone());
        }
    }
    index
}

// Test di integrazione per la funzione di indicizzazione
#[test]
fn test_index_documents() {
    let documents = vec!["Hello world".to_string(), "Rust is great".to_string()];
    let index = index_documents(documents);
    assert!(index.contains_key("Hello"));
    assert!(index.contains_key("Rust"));
}

// Benchmark per la funzione di indicizzazione
#[bench]
fn bench_index_documents(b: &mut Bencher) {
    let documents = vec!["Hello world".to_string(); 1000];
    b.iter(|| index_documents(documents.clone()));
}
```

## Risorse

- [The Rust Book - Testing](https://doc.rust-lang.org/book/ch11-00-testing.html)
- [Rust by Example - Testing](https://doc.rust-lang.org/rust-by-example/testing.html)
- [Rust Documentation - Benchmarking](https://doc.rust-lang.org/unstable-book/library-features/test.html)

## Esercizio

Scrivi un test unitario per una funzione che calcola la frequenza delle parole in un documento. La funzione dovrebbe prendere una stringa come input e restituire una mappa dove le chiavi sono le parole e i valori sono le loro frequenze. Successivamente, scrivi un test di integrazione per verificare che la funzione di calcolo della frequenza delle parole interagisca correttamente con la funzione di tokenizzazione.