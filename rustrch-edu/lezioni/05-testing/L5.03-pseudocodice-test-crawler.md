## Teoria

I test per il crawler sono essenziali per garantire che il componente di crawling del motore di ricerca funzioni correttamente. Il crawler è responsabile della navigazione e dell'indicizzazione delle pagine web, quindi è cruciale che sia robusto e affidabile. I test per il crawler possono essere suddivisi in diverse categorie, tra cui test di unità, test di integrazione e test end-to-end. In questa sezione, ci concentreremo sulla scrittura di pseudocodice per i test del crawler, che aiuterà a pianificare e strutturare i test prima di implementarli effettivamente.

Lo pseudocodice è particolarmente utile in questa fase perché consente di definire la logica dei test senza dover scrivere codice compilabile. Questo approccio aiuta a identificare potenziali problemi e a chiarire i requisiti dei test. Ad esempio, possiamo definire come il crawler dovrebbe gestire diverse situazioni, come pagine web non valide, collegamenti interrotti o contenuti dinamici.

## Esempio

Supponiamo di avere un crawler che deve navigare attraverso un sito web e indicizzare le pagine. Un test tipico potrebbe verificare che il crawler riesca a recuperare correttamente il contenuto di una pagina web e a estrarre i collegamenti ipertestuali. Ecco un esempio di come potrebbe essere strutturato il test:

1. **Setup**: Configurare un server web locale con pagine di test.
2. **Esecuzione**: Avviare il crawler e puntarlo all'URL della pagina di test.
3. **Verifica**: Controllare che il crawler abbia recuperato correttamente il contenuto della pagina e abbia estratto tutti i collegamenti ipertestuali.

## Pseudocodice

Ecco uno pseudocodice che illustra come scrivere test per il crawler:

```rust
// Definizione della funzione del crawler
fn crawler(url: &str) -> Result<Vec<String>, String> {
    // Logica del crawler
    // Recupera il contenuto della pagina web
    // Estrae i collegamenti ipertestuali
    // Restituisce i collegamenti trovati
}

// Modulo di test per il crawler
#[cfg(test)]
mod tests {
    use super::*;

    // Test per verificare che il crawler recuperi correttamente il contenuto di una pagina web
    #[test]
    fn test_crawler_recupera_contenuto() {
        // Setup del test
        let url = "http://localhost:8080/test-page";
        let contenuto_atteso = "<html><body>Test Page</body></html>";

        // Esecuzione del crawler
        let risultato = crawler(url);

        // Verifica del risultato
        assert!(risultato.is_ok());
        let contenuto_ottenuto = risultato.unwrap();
        assert_eq!(contenuto_ottenuto, contenuto_atteso);
    }

    // Test per verificare che il crawler estragga correttamente i collegamenti ipertestuali
    #[test]
    fn test_crawler_estrae_collegamenti() {
        // Setup del test
        let url = "http://localhost:8080/test-page-with-links";
        let collegamenti_attesi = vec!["http://localhost:8080/link1", "http://localhost:8080/link2"];

        // Esecuzione del crawler
        let risultato = crawler(url);

        // Verifica del risultato
        assert!(risultato.is_ok());
        let collegamenti_ottenuti = risultato.unwrap();
        assert_eq!(collegamenti_ottenuti, collegamenti_attesi);
    }

    // Test per verificare che il crawler gestisca correttamente le pagine web non valide
    #[test]
    fn test_crawler_gestisce_pagine_non_valide() {
        // Setup del test
        let url = "http://localhost:8080/non-existent-page";

        // Esecuzione del crawler
        let risultato = crawler(url);

        // Verifica del risultato
        assert!(risultato.is_err());
    }
}
```

## Risorse

- [Documentazione ufficiale di Rust sui test](https://doc.rust-lang.org/book/ch11-01-writing-tests.html)
- [Rust by Example: Testing](https://doc.rust-lang.org/rust-by-example/testing/unit_testing.html)
- [Crates.io: librerie per il testing](https://crates.io/crates/test)

## Esercizio

Scrivi uno pseudocodice per un test che verifichi che il crawler gestisca correttamente i collegamenti interrotti. Assicurati di includere i passaggi principali che seguirai per scrivere questo test. Quali sono le condizioni che il crawler dovrebbe verificare per identificare un collegamento interrotto?