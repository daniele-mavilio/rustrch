## Teoria

La tokenizzazione è il processo di suddivisione di un testo in unità più piccole, chiamate token, che rappresentano parole, frasi o simboli significativi. Questo passaggio è fondamentale nella costruzione di un motore di ricerca, poiché consente di analizzare e indicizzare il contenuto in modo efficiente. Durante la tokenizzazione, il testo viene pulito e normalizzato: vengono rimosse le stopword (parole comuni come "il", "e", "di" che non aggiungono significato al contenuto), e si applica lo stemming, che riduce le parole alla loro forma base (ad esempio, "correndo" diventa "correre").

La tokenizzazione non è un processo banale, poiché deve gestire correttamente diversi casi, come le parole compostate, le abbreviazioni, i numeri e i simboli speciali. Ad esempio, in un testo come "L'IA è il futuro", la tokenizzazione dovrebbe separare "L'IA" in due token distinti, "L'" e "IA", oppure trattare "L'IA" come un unico token, a seconda delle esigenze del motore di ricerca. Inoltre, la gestione delle maiuscole e minuscole è cruciale: "Rust" e "rust" potrebbero essere considerati token diversi o essere normalizzati alla stessa forma.

Un altro aspetto importante della tokenizzazione è la gestione delle lingue diverse. Ogni lingua ha le sue peculiarità, come le stopword specifiche e le regole di stemming. Ad esempio, in italiano, le stopword includono parole come "il", "la", "e", "di", mentre in inglese includono "the", "and", "of". Lo stemming, invece, deve essere adattato alle regole grammaticali della lingua specifica.

## Esempio

Consideriamo un testo di esempio: "Il motore di ricerca è uno strumento fondamentale per trovare informazioni su Internet. Utilizzando algoritmi avanzati, è possibile ottenere risultati pertinenti in pochi secondi.".

1. **Rimozione delle stopword**: Le parole come "il", "di", "è", "uno", "per", "su", "in" vengono rimosse, lasciando "motore ricerca strumento fondamentale trovare informazioni Internet. Utilizzando algoritmi avanzati, possibile ottenere risultati pertinenti pochi secondi.".

2. **Stemming**: Le parole vengono ridotte alla loro forma base. Ad esempio, "trovare" diventa "trov", "utilizzando" diventa "util", "avanzati" diventa "avanz", "ottenere" diventa "otten", "pertinenti" diventa "pertin", "secondi" diventa "second".

3. **Tokenizzazione finale**: Il testo viene suddiviso in token: ["motore", "ricerca", "strumento", "fondamentale", "trov", "informazioni", "Internet", "util", "algoritmi", "avanz", "possibile", "otten", "risultati", "pertin", "pochi", "second"].

Questo processo consente al motore di ricerca di indicizzare il testo in modo efficiente e di recuperare informazioni pertinenti in risposta a una query.

## Pseudocodice

```rust
// Definizione di una funzione per la tokenizzazione di un testo
fn tokenize(text: &str) -> Vec<String> {
    // 1. Converti il testo in minuscolo per normalizzare
    let text = text.to_lowercase();
    
    // 2. Rimuovi la punteggiatura e i simboli speciali
    let text = text.replace(|c: char| !c.is_alphanumeric(), " ");
    
    // 3. Suddividi il testo in parole
    let words: Vec<&str> = text.split_whitespace().collect();
    
    // 4. Rimuovi le stopword
    let stopwords = ["il", "di", "e", "è", "uno", "per", "su", "in"];
    let filtered_words: Vec<&str> = words
        .into_iter()
        .filter(|word| !stopwords.contains(word))
        .collect();
    
    // 5. Applica lo stemming (esempio semplificato)
    let stemmed_words: Vec<String> = filtered_words
        .into_iter()
        .map(|word| {
            if word.ends_with("ando") {
                word[..word.len() - 3].to_string()
            } else if word.ends_with("endo") {
                word[..word.len() - 3].to_string()
            } else {
                word.to_string()
            }
        })
        .collect();
    
    // 6. Restituisci i token
    stemmed_words
}

// Esempio di utilizzo della funzione tokenize
fn main() {
    let text = "Il motore di ricerca è uno strumento fondamentale per trovare informazioni su Internet.";
    let tokens = tokenize(text);
    println!("{:?}", tokens);
}
```

## Risorse

- [Tokenizzazione in Rust - Documentazione ufficiale](https://doc.rust-lang.org/book/ch08-02-strings.html)
- [Libreria `tokenizers` per Rust](https://crates.io/crates/tokenizers)
- [Stemming in Rust - Algoritmi e implementazioni](https://docs.rs/stemmer/0.1.0/stemmer/)

## Esercizio

Scrivi una funzione in Rust che implementi la tokenizzazione di un testo, includendo la rimozione delle stopword e lo stemming. Utilizza un approccio modulare, suddividendo il processo in funzioni separate per ogni passaggio (normalizzazione, rimozione punteggiatura, rimozione stopword, stemming).

**Traccia di soluzione:**
1. Definisci una funzione `normalize_text` che converta il testo in minuscolo.
2. Definisci una funzione `remove_punctuation` che rimuova la punteggiatura e i simboli speciali.
3. Definisci una funzione `remove_stopwords` che filtri le stopword.
4. Definisci una funzione `apply_stemming` che applichi lo stemming alle parole.
5. Combina queste funzioni in una funzione `tokenize` che restituisca i token finali.