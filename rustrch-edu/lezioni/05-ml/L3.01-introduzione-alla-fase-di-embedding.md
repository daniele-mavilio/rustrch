# Introduzione alla Fase di Embedding

## Teoria

Benvenuti nella terza fase del nostro corso su come costruire un motore di ricerca in Rust. In questa fase, ci concentreremo sulla generazione di embedding, un concetto fondamentale per la ricerca semantica. Gli embedding sono rappresentazioni vettoriali di testo che catturano il significato semantico delle parole e dei documenti. Questo ci permetterà di andare oltre la semplice ricerca per keyword e di trovare documenti che sono semanticamente simili alla query dell'utente, anche se non contengono le stesse parole chiave.

La ricerca semantica è particolarmente utile quando si tratta di linguaggio naturale, dove sinonimi, parole correlate e contesti possono giocare un ruolo cruciale nella pertinenza dei risultati. Ad esempio, se un utente cerca "automobile", un motore di ricerca semantico può trovare documenti che parlano di "macchina" o "veicolo", anche se questi termini non sono presenti nella query.

In questa fase, impareremo:

1. **Cos'è un Embedding**: Comprenderemo cosa sono gli embedding e come rappresentano il significato semantico del testo.
2. **Machine Learning in Rust**: Esploreremo come utilizzare modelli di machine learning pre-addestrati in Rust per generare embedding.
3. **ONNX Runtime**: Impareremo a utilizzare ONNX Runtime per caricare e eseguire modelli di machine learning in Rust.
4. **Similarità del Coseno**: Studieremo come calcolare la similarità tra embedding utilizzando la similarità del coseno.

## Esempio

Immaginiamo di avere un motore di ricerca che deve trovare documenti relativi alla programmazione in Rust. Un utente potrebbe cercare "linguaggio di programmazione Rust". Un motore di ricerca tradizionale basato su keyword potrebbe trovare documenti che contengono esattamente queste parole. Tuttavia, un motore di ricerca semantico può trovare documenti che parlano di "sviluppo software con Rust" o "programmazione in Rust", anche se non contengono la parola "linguaggio".

Ad esempio, consideriamo i seguenti documenti:

1. "Rust è un linguaggio di programmazione moderno e sicuro."
2. "La programmazione in Rust offre prestazioni elevate e sicurezza."
3. "Sviluppare software con Rust è un'esperienza gratificante."

Un motore di ricerca semantico può trovare tutti e tre i documenti come rilevanti per la query "linguaggio di programmazione Rust", anche se solo il primo documento contiene esattamente le parole chiave.

## Pseudocodice

Ecco uno pseudocodice che illustra come potremmo generare e utilizzare gli embedding in un motore di ricerca:

```rust
// Carica il modello di embedding
funzione carica_modello(percorso_modello: &str) -> Modello {
    // Utilizza ONNX Runtime per caricare il modello
    let sessione = onnx::carica(percorso_modello);
    Modello { sessione }
}

// Genera un embedding per un dato testo
funzione genera_embedding(modello: &Modello, testo: &str) -> Vec<f32> {
    // Tokenizza il testo
    let tokens = tokenizza(testo);
    
    // Prepara l'input per il modello
    let input = prepara_input(tokens);
    
    // Esegui l'inferenza
    let output = modello.sessione.esegui(input);
    
    // Estrai l'embedding dall'output
    let embedding = output.estrai_embedding();
    embedding
}

// Calcola la similarità tra due embedding
funzione similarita_coseno(a: &Vec<f32>, b: &Vec<f32>) -> f32 {
    let prodotto_scalare = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum::<f32>();
    let norma_a = (a.iter().map(|x| x * x).sum::<f32>()).sqrt();
    let norma_b = (b.iter().map(|x| x * x).sum::<f32>()).sqrt();
    
    prodotto_scalare / (norma_a * norma_b)
}

// Cerca documenti simili a una query
funzione cerca_simili(modello: &Modello, query: &str, documenti: &[Documento]) -> Vec<(Documento, f32)> {
    let query_embedding = genera_embedding(modello, query);
    
    documenti.iter()
        .map(|doc| {
            let doc_embedding = genera_embedding(modello, &doc.contenuto);
            let similarita = similarita_coseno(&query_embedding, &doc_embedding);
            (doc.clone(), similarita)
        })
        .filter(|(_, similarita)| *similarita > 0.5) // Filtra risultati con similarità > 0.5
        .collect()
}
```

## Risorse

Ecco alcune risorse utili per approfondire gli argomenti trattati in questa fase:

1. [ONNX Runtime Documentation](https://onnxruntime.ai/)
2. [Sentence Transformers](https://www.sbert.net/)
3. [Understanding Embeddings](https://jalammar.github.io/illustrated-word2vec/)
4. [Cosine Similarity Explained](https://en.wikipedia.org/wiki/Cosine_similarity)

## Esercizio

Per consolidare quanto appreso, prova a rispondere alle seguenti domande:

1. **Cos'è un embedding e come rappresenta il significato semantico del testo?**
2. **Qual è la differenza tra un motore di ricerca basato su keyword e uno basato su embedding?**
3. **Come funziona la similarità del coseno e perché è utile per confrontare embedding?**

**Traccia di soluzione:**

1. Un embedding è un vettore di numeri che rappresenta il significato semantico di un testo. Ogni dimensione del vettore cattura un aspetto del significato, permettendo di confrontare testi in base alla loro similarità semantica.

2. Un motore di ricerca basato su keyword trova documenti che contengono esattamente le parole chiave della query, mentre un motore basato su embedding trova documenti che sono semanticamente simili alla query, anche se non contengono le stesse parole chiave.

3. La similarità del coseno misura l'angolo tra due vettori. Un valore di 1 indica che i vettori sono identici, mentre un valore di 0 indica che sono ortogonali. È utile per confrontare embedding perché misura quanto sono simili semanticamente.
