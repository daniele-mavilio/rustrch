## Teoria

La fase di ricerca è uno dei momenti più critici nella costruzione di un motore di ricerca. Fino a questo punto, abbiamo imparato a raccogliere dati (crawling), a organizzarli in strutture efficienti (indicizzazione), e a rappresentarli in forma vettoriale (embedding). Ora, però, dobbiamo rispondere a una domanda fondamentale: come facciamo a trovare i documenti più rilevanti per una determinata query?

In questa lezione, introdurremo il concetto di ricerca ibrida, una tecnica che combina due approcci fondamentali: la ricerca basata su keyword (BM25) e la ricerca semantica (embedding). Ogni approccio ha i suoi punti di forza e di debolezza, e capire quando e come utilizzarli è essenziale per costruire un motore di ricerca efficace.

La ricerca basata su keyword, come quella implementata dall'algoritmo BM25, è eccellente per trovare documenti che contengono esattamente le parole chiave della query. Questo approccio è particolarmente utile quando l'utente sa esattamente cosa sta cercando e usa termini specifici. Tuttavia, BM25 ha un limite: non riesce a catturare il significato semantico delle parole. Ad esempio, se cerchiamo "auto", BM25 non troverà documenti che parlano di "macchine" o "veicoli", anche se semanticamente sono molto simili.

D'altra parte, la ricerca semantica, basata su embedding, è in grado di catturare il significato delle parole e delle frasi. Utilizzando modelli di machine learning, possiamo rappresentare le parole e i documenti come vettori in uno spazio semantico. In questo spazio, parole con significati simili saranno vicine tra loro, permettendo di trovare documenti rilevanti anche se non contengono esattamente le parole chiave della query. Tuttavia, la ricerca semantica può essere meno precisa quando l'utente usa termini molto specifici o tecnici.

La ricerca ibrida combina i punti di forza di entrambi gli approcci. Utilizzando una combinazione di BM25 e embedding, possiamo ottenere risultati che sono sia precisi che semanticamente rilevanti. Questo approccio è particolarmente utile in contesti dove la precisione e la comprensione del significato sono entrambe importanti, come nella ricerca di documenti tecnici o nella ricerca di informazioni mediche.

## Esempio

Immaginiamo di voler cercare informazioni su come costruire un motore di ricerca in Rust. Se utilizziamo solo BM25, potremmo ottenere risultati che contengono esattamente le parole "motore di ricerca" e "Rust", ma potremmo perdere documenti che parlano di "costruire un motore di ricerca" o "implementare un motore di ricerca in Rust".

D'altra parte, se utilizziamo solo la ricerca semantica, potremmo ottenere documenti che parlano di "costruire un motore di ricerca" o "implementare un motore di ricerca in Rust", ma potremmo anche ottenere documenti che parlano di "motori di ricerca in generale" o "come funziona un motore di ricerca", che potrebbero non essere rilevanti per la nostra query specifica.

Utilizzando la ricerca ibrida, possiamo combinare i risultati di entrambi gli approcci per ottenere i documenti più rilevanti. Ad esempio, potremmo dare un peso maggiore ai documenti che contengono esattamente le parole chiave della query (utilizzando BM25) e un peso minore ai documenti che sono semanticamente simili (utilizzando embedding). In questo modo, otteniamo risultati che sono sia precisi che semanticamente rilevanti.

## Pseudocodice

```rust
// Definizione di una struttura per rappresentare un documento
struct Document {
    id: u32,
    content: String,
    // Altri campi rilevanti per il documento
}

// Definizione di una struttura per rappresentare una query
struct Query {
    text: String,
    // Altri campi rilevanti per la query
}

// Funzione per calcolare il punteggio BM25 per un documento rispetto a una query
fn calculate_bm25_score(document: &Document, query: &Query) -> f32 {
    // Implementazione dell'algoritmo BM25
    // Restituisce un punteggio che rappresenta la rilevanza del documento per la query
    0.0
}

// Funzione per calcolare la similarità semantica tra un documento e una query
fn calculate_semantic_similarity(document: &Document, query: &Query) -> f32 {
    // Implementazione della similarità semantica utilizzando embedding
    // Restituisce un punteggio che rappresenta la similarità semantica tra il documento e la query
    0.0
}

// Funzione per combinare i punteggi BM25 e semantico
fn combine_scores(bm25_score: f32, semantic_score: f32, alpha: f32) -> f32 {
    // Combina i punteggi utilizzando un peso alpha
    // alpha rappresenta il peso da dare al punteggio BM25 rispetto al punteggio semantico
    alpha * bm25_score + (1.0 - alpha) * semantic_score
}

// Funzione principale per eseguire la ricerca ibrida
fn hybrid_search(documents: &[Document], query: &Query, alpha: f32) -> Vec<(u32, f32)> {
    let mut results = Vec::new();
    
    for document in documents {
        let bm25_score = calculate_bm25_score(document, query);
        let semantic_score = calculate_semantic_similarity(document, query);
        let combined_score = combine_scores(bm25_score, semantic_score, alpha);
        
        results.push((document.id, combined_score));
    }
    
    // Ordina i risultati in base al punteggio combinato
    results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
    
    results
}
```

## Risorse

1. [The Rust Book - Capitolo su Algoritmi](https://doc.rust-lang.org/book/ch00-00-introduction.html)
2. [Documentazione di BM25](https://en.wikipedia.org/wiki/Okapi_BM25)
3. [Introduzione agli Embedding](https://en.wikipedia.org/wiki/Word_embedding)

## Esercizio

Immagina di dover implementare una funzione che combini i punteggi di BM25 e di similarità semantica. Quali fattori dovresti considerare per determinare il valore di alpha? Scrivi una breve spiegazione e un esempio di come potresti calcolare alpha in base alla lunghezza della query o alla presenza di termini specifici.